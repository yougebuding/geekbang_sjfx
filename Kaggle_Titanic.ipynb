{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "df1_train = pd.read_csv('/Users/apple/Desktop/titanic/train.csv')\n",
    "df1_test = pd.read_csv('/Users/apple/Desktop/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 第一模块：数据探索，查看表的基本情况，有多少行，多少列，各列的数据类型、完整度；\n",
    "print(type(list(df1_train.columns[2:4])))\n",
    "print('-'*30)\n",
    "print(df1_train.info())\n",
    "print('-'*30)\n",
    "print(df1_test.info())\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 对于数值型数据，查看其基本情况（个数、均值、最大最小值等）\n",
    "print(df1_train.describe())\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Name   Sex Ticket    Cabin Embarked\n",
      "count                     891   891    891      204      889\n",
      "unique                    891     2    681      147        3\n",
      "top     Cairns, Mr. Alexander  male   1601  B96 B98        S\n",
      "freq                        1   577      7        4      644\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 对于字符串数据，查看其基本情况（个数、非重复个数、频数最高者、频次）\n",
    "print(df1_train.describe(include=['O']))\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 对于整个表格，查看前 5行数据\n",
    "print(df1_train.head())\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          891 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          418 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         418 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 第二模块：数据清洗、重点--补充缺失值\n",
    "# 对于数值型字段，用其均值 补充缺失值\n",
    "df1_train.fillna(df1_train.mean(),inplace=True)\n",
    "df1_test.fillna(df1_test.mean(axis = 0),inplace=True)\n",
    "print(df1_train.info())\n",
    "print(df1_test.info())\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 查看存在缺失值的字符串字段，各非重复值，及相应个数，按频次降序排列，并补充缺失值=频次最高者\n",
    "print(df1_train['Embarked'].value_counts())\n",
    "df1_train['Embarked'].fillna('S',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass     Sex        Age  SibSp  Parch     Fare Embarked\n",
      "0         3    male  22.000000      1      0   7.2500        S\n",
      "1         1  female  38.000000      1      0  71.2833        C\n",
      "2         3  female  26.000000      0      0   7.9250        S\n",
      "3         1  female  35.000000      1      0  53.1000        S\n",
      "4         3    male  35.000000      0      0   8.0500        S\n",
      "..      ...     ...        ...    ...    ...      ...      ...\n",
      "886       2    male  27.000000      0      0  13.0000        S\n",
      "887       1  female  19.000000      0      0  30.0000        S\n",
      "888       3  female  29.699118      1      2  23.4500        S\n",
      "889       1    male  26.000000      0      0  30.0000        C\n",
      "890       3    male  32.000000      0      0   7.7500        Q\n",
      "\n",
      "[891 rows x 7 columns]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 第三模块：模型的 特征选择\n",
    "# 对于该案例，选择 Pclass、Sex、Age、SibSp、Parch、Ticket、Fare、Embarked 作为特征;Survived 作为标签\n",
    "features = ['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']\n",
    "train_features = df1_train[features]\n",
    "print(train_features)\n",
    "train_labels = df1_train['Survived']\n",
    "test_features = df1_test[features]\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将所有字符串数据，变为 数值型\n",
    "# 将字符串字段 处理成 数值型，使用 Sklearn 特征选择里的 DictVectorizer,并转换成 特征值矩阵\n",
    "# 即，Embarked单独的一列，拆开变成 'Embarked = S'、'Embarked = C'、'Embarked = Q' 3列的值，这3列分别为 0/1\n",
    "# 而，Sex 这一单独列，拆开变成 'Sex = female'、'Sex = male' 2列的值，也均为 0/1 的值\n",
    "# 所以，原来 train_features 仅有 7列，这样，即 扩展为 10列,891行\n",
    "dvec = DictVectorizer(sparse=False)\n",
    "train_features = dvec.fit_transform(train_features.to_dict(orient='record'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据规范化（只能等所有 数据变为 数值型的才可规范，若含有 字符串型，直接规范会出错）\n",
    "# 此为 Z-Score 规范化，使得每个特征数据，均值为0，方差为1\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_features)\n",
    "train_features = ss.transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第四模块：构造分类器\n",
    "# 鉴于此为分类模型，先采取 决策树模型，即 sklearn的 tree里的 DecisionTreeClassifier\n",
    "# 当标准 criterion = 'entropy'时，即为 熵增--ID3模型；若为 criterion = 'gini'时，即为 基尼--CART模型\n",
    "\n",
    "# 构造 决策树分类器 中的 ID3模型\n",
    "clf_id3 = DecisionTreeClassifier(criterion='entropy')\n",
    "# 训练模型\n",
    "clf_id3.fit(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树ID3 K折交叉验证准确率为 0.7779\n",
      "决策树ID3 自带的score函数 准确率为 0.9820\n"
     ]
    }
   ],
   "source": [
    "# 第五模块：模型预测 & 预测结果评估\n",
    "# 一方面，我们可以将 train数据，先分割成 train & test 2份数据，用train的模型去测量 test准确率；\n",
    "# 另一方面，我们可以 用 K折交叉验证，即，model_selection 里的 cross_val_score\n",
    "# 所以这里我们先用 K折交叉验证，来统计决策树模型的准确率；同时比较下 决策树自带的 score函数 测量的准确率\n",
    "print('决策树ID3 K折交叉验证准确率为 %.4f' % np.mean(cross_val_score(clf_id3,train_features,train_labels,cv=10)))\n",
    "print('决策树ID3 自带的score函数 准确率为 %.4f' % (clf_id3.score(train_features,train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树ID3 metrics里的 一般 accuracy_score 准确率为 0.9820\n"
     ]
    }
   ],
   "source": [
    "# 当然，决策树自带的 score函数，与 metrics 里的 accuracy_score 函数结果一样\n",
    "train_pre = clf_id3.predict(train_features)\n",
    "score = round(accuracy_score(train_labels,train_pre),6)\n",
    "print('决策树ID3 metrics里的 一般 accuracy_score 准确率为 %.4f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 用 模拟好的模型，预测 test表的结果\n",
    "# 首先也是将 test表字符串字段 转为 数值型，由于之前 dvec已经 fit_transform了，所以这里可以直接 transform\n",
    "test_features = dvec.transform(test_features.to_dict(orient='record'))\n",
    "test_features = ss.transform(test_features)\n",
    "test_pre_clf_id3 = clf_id3.predict(test_features)\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树弱分类器中 K折交叉验证准确率为 0.7867\n",
      "决策树弱分类器 自带的score函数 准确率为 0.7868\n",
      "决策树弱分类器中 metrics里的 一般 accuracy_score 准确率为 0.7868\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 构造 决策树弱分类器 & 模型预测结果评估:\n",
    "clf_ruo = DecisionTreeClassifier(max_depth=1,min_samples_leaf=1,random_state=1)\n",
    "clf_ruo.fit(train_features,train_labels)\n",
    "print('决策树弱分类器中 K折交叉验证准确率为 %.4f' % np.mean(cross_val_score(clf_ruo,train_features,train_labels,cv=10)))\n",
    "print('决策树弱分类器 自带的score函数 准确率为 %.4f' % (clf_ruo.score(train_features,train_labels)))\n",
    "train_pre = clf_ruo.predict(train_features)\n",
    "score = round(accuracy_score(train_labels,train_pre),6)\n",
    "print('决策树弱分类器中 metrics里的 一般 accuracy_score 准确率为 %.4f' % score)\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树CART分类器中 K折交叉验证准确率为 0.7756\n",
      "决策树CART分类器 自带的score函数 准确率为 0.9820\n",
      "决策树CART分类器中 metrics里的 一般 accuracy_score 准确率为 0.9820\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 构造 决策树CART分类器 & 模型预测结果评估\n",
    "clf_cart = DecisionTreeClassifier(criterion='gini',random_state=1)\n",
    "clf_cart.fit(train_features,train_labels)\n",
    "print('决策树CART分类器中 K折交叉验证准确率为 %.4f' % np.mean(cross_val_score(clf_cart,train_features,train_labels,cv=10)))\n",
    "print('决策树CART分类器 自带的score函数 准确率为 %.4f' % (clf_cart.score(train_features,train_labels)))\n",
    "train_pre = clf_cart.predict(train_features)\n",
    "score = round(accuracy_score(train_labels,train_pre),6)\n",
    "print('决策树CART分类器中 metrics里的 一般 accuracy_score 准确率为 %.4f' % score)\n",
    "test_pre_clf_cart = clf_cart.predict(test_features)\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM分类器中 K折交叉验证准确率为 0.8249\n",
      "SVM分类器 自带的score函数 准确率为 0.8429\n",
      "SVM分类器中 metrics里的 一般 accuracy_score 准确率为 0.8429\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 构造 SVM的分类器 & 模型预测结果评估\n",
    "svc = SVC(random_state=1)\n",
    "svc.fit(train_features,train_labels)\n",
    "print('SVM分类器中 K折交叉验证准确率为 %.4f' % np.mean(cross_val_score(svc,train_features,train_labels,cv=10)))\n",
    "print('SVM分类器 自带的score函数 准确率为 %.4f' % (svc.score(train_features,train_labels)))\n",
    "train_pre = svc.predict(train_features)\n",
    "score = round(accuracy_score(train_labels,train_pre),6)\n",
    "print('SVM分类器中 metrics里的 一般 accuracy_score 准确率为 %.4f' % score)\n",
    "test_pre_svc = svc.predict(test_features)\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "高斯朴素贝叶斯 分类器中 K折交叉验证准确率为 0.7845\n",
      "高斯朴素贝叶斯分类器 自带的score函数 准确率为 0.7912\n",
      "高斯朴素贝叶斯分类器中 metrics里的 一般 accuracy_score 准确率为 0.7912\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 构造 高斯分类器 & 模型预测结果评估\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_features,train_labels)\n",
    "print('高斯朴素贝叶斯 分类器中 K折交叉验证准确率为 %.4f' % np.mean(cross_val_score(gnb,train_features,train_labels,cv=10)))\n",
    "print('高斯朴素贝叶斯分类器 自带的score函数 准确率为 %.4f' % (gnb.score(train_features,train_labels)))\n",
    "train_pre = gnb.predict(train_features)\n",
    "score = round(accuracy_score(train_labels,train_pre),6)\n",
    "print('高斯朴素贝叶斯分类器中 metrics里的 一般 accuracy_score 准确率为 %.4f' % score)\n",
    "test_pre_gnb = gnb.predict(test_features)\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K近邻 分类器中 K折交叉验证准确率为 0.8204\n",
      "K近邻 分类器 自带的score函数 准确率为 0.8361\n",
      "K近邻 分类器中 metrics里的 一般 accuracy_score 准确率为 0.8361\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 构造 Knn--K近邻分类器 & 模型预测结果评估\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "knn.fit(train_features,train_labels)\n",
    "print('K近邻 分类器中 K折交叉验证准确率为 %.4f' % np.mean(cross_val_score(knn,train_features,train_labels,cv=10)))\n",
    "print('K近邻 分类器 自带的score函数 准确率为 %.4f' % (knn.score(train_features,train_labels)))\n",
    "train_pre = knn.predict(train_features)\n",
    "score = round(accuracy_score(train_labels,train_pre),6)\n",
    "print('K近邻 分类器中 metrics里的 一般 accuracy_score 准确率为 %.4f' % score)\n",
    "test_pre_knn = knn.predict(test_features)\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost分类器中 K折交叉验证准确率为 0.8115\n",
      "AdaBoost分类器 自带的score函数 准确率为 0.8485\n",
      "AdaBoost分类器中 metrics里的 一般 accuracy_score 准确率为 0.8485\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 构造 Adaboost分类器 & 模型预测结果评估:设置 该算法最大迭代次数为200，默认则是 50;默认弱分类器采用的是 决策树；\n",
    "ada = AdaBoostClassifier(n_estimators=200,random_state=1)\n",
    "ada.fit(train_features,train_labels)\n",
    "print('AdaBoost分类器中 K折交叉验证准确率为 %.4f' % np.mean(cross_val_score(ada,train_features,train_labels,cv=10)))\n",
    "print('AdaBoost分类器 自带的score函数 准确率为 %.4f' % (ada.score(train_features,train_labels)))\n",
    "train_pre = ada.predict(train_features)\n",
    "score = round(accuracy_score(train_labels,train_pre),6)\n",
    "print('AdaBoost分类器中 metrics里的 一般 accuracy_score 准确率为 %.4f' % score)\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 test结果插入到 test原表中\n",
    "# data.insert(列的索引位置，列名，列值）\n",
    "df1_test.insert(0,'Survived_clf_id3',test_pre_clf_id3)\n",
    "df1_test.insert(1,'Survived_clf_cart',test_pre_clf_cart)\n",
    "df1_test.insert(2,'Survived_svc',test_pre_svc)\n",
    "df1_test.insert(3,'Survived_gnb',test_pre_gnb)\n",
    "df1_test.insert(4,'Survived_knn',test_pre_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别输出完整版 test结果，及，简化版 test结果\n",
    "bq = ['Survived_clf_id3','Survived_clf_cart','Survived_svc','Survived_gnb','Survived_knn','PassengerId','Name']\n",
    "jhb = df1_test[bq]\n",
    "# 加入井号键，先不输出\n",
    "# df1_test.to_csv('titanic_test_result.csv')\n",
    "# jhb.to_csv('/Users/apple/Desktop/titanic/titanic_test_result_jhb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
